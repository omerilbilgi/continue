import { AssistantUnrolled } from "@continuedev/config-yaml";

export const defaultConfigYaml: AssistantUnrolled = {
  name: "AIRS Coder",
  version: "1.0.0",
  schema: "v1",
  models: [
    {
      name: "AIRS Coder Model",
      provider: "ollama",
      model: "qwen3-serve-40k:latest",
      apiBase: "http://172.17.200.54:11437",
      capabilities: ["tool_use", "reasoning"],
      roles: ["autocomplete", "chat", "edit", "apply"],
    },
    {
      name: "Qwen3-Coder-30B-vLLM",
      provider: "openai",
      model: "qwen-coder-30b",
      apiBase: "http://localhost:8000/v1",
      roles: [],
      capabilities: ["tool_use"],
      defaultCompletionOptions: {
        temperature: 0.2,
        maxTokens: 4096,
      },
    },
    {
      name: "Qwen3-8B-vLLM",
      provider: "openai",
      model: "qwen3-8b",
      apiBase: "http://localhost:8000/v1",
      roles: [],
      defaultCompletionOptions: {
        temperature: 0.2,
        maxTokens: 4096,
      },
    },
    {
      name: "Qwen3-Coder-30B",
      provider: "ollama",
      model: "qwen3-coder:30b",
      apiBase: "http://172.17.200.54:11434",
      capabilities: ["tool_use"],
      roles: [],
    },
    {
      name: "GPT-OSS-20b",
      provider: "ollama",
      model: "gpt-oss:latest",
      apiBase: "http://172.17.200.54:11434",
      roles: [],
      capabilities: ["tool_use", "reasoning"],
      defaultCompletionOptions: {
        temperature: 0.6,
        maxTokens: 1024,
        stream: true,
        reasoning: true,
      },
    },
    {
      name: "GPT-OSS-120B-16k",
      provider: "ollama",
      model: "gpt-oss:120B-16k",
      apiBase: "http://172.17.200.54:11434",
      roles: [],
      capabilities: ["tool_use", "reasoning"],
      defaultCompletionOptions: {
        temperature: 0.6,
        maxTokens: 1024,
        stream: true,
        reasoning: true,
      },
    },
    {
      name: "GPT-OSS-120B-64k",
      provider: "ollama",
      model: "gpt-oss:120B-64k",
      apiBase: "http://172.17.200.54:11434",
      roles: [],
      capabilities: ["tool_use", "reasoning"],
      defaultCompletionOptions: {
        temperature: 0.6,
        maxTokens: 1024,
        stream: true,
        reasoning: true,
      },
    },
    {
      name: "Qwen2.5",
      provider: "ollama",
      model: "qwen2.5-coder-custom:latest",
      apiBase: "http://172.17.200.54:11437",
      capabilities: ["tool_use"],
      roles: ["autocomplete"],
    },
    {
      name: "Instinct",
      provider: "ollama",
      model: "nate/instinct:latest",
      apiBase: "http://172.17.200.54:11437",
      capabilities: ["tool_use"],
      roles: ["autocomplete"],
    },
  ],
  context: [],
};

export const defaultConfigYamlJetBrains: AssistantUnrolled = {
  name: "AIRS.",
  version: "1.0.0",
  schema: "v1",
  models: [
    {
      name: "AIRS Coder Model",
      provider: "ollama",
      model: "qwen3-serve-40k:latest",
      apiBase: "http://172.17.200.54:11437",
      capabilities: ["tool_use", "reasoning"],
      roles: ["autocomplete", "chat", "edit", "apply"],
    },
    {
      name: "Qwen3-Coder-30B-vLLM",
      provider: "openai",
      model: "qwen-coder-30b",
      apiBase: "http://localhost:8000/v1",
      roles: ["chat", "edit", "apply"],
      capabilities: ["tool_use"],
      defaultCompletionOptions: {
        temperature: 0.2,
        maxTokens: 4096,
      },
    },
    {
      name: "Qwen3-Coder-30B",
      provider: "ollama",
      model: "qwen3-coder:30b",
      apiBase: "http://172.17.200.54:11434",
      capabilities: ["tool_use"],
      roles: ["chat", "edit", "apply"],
    },
    {
      name: "GPT-OSS-8k",
      provider: "ollama",
      model: "gpt-oss:120B",
      apiBase: "http://172.17.200.54:11434",
      roles: ["chat", "autocomplete", "edit", "apply"],
      capabilities: ["tool_use", "reasoning"],
      defaultCompletionOptions: {
        temperature: 0.6,
        maxTokens: 1024,
        stream: true,
        reasoning: true,
      },
    },
    {
      name: "GPT-OSS-120B-16k",
      provider: "ollama",
      model: "gpt-oss:120B-16k",
      apiBase: "http://172.17.200.54:11434",
      roles: [],
      capabilities: ["tool_use", "reasoning"],
      defaultCompletionOptions: {
        temperature: 0.6,
        maxTokens: 1024,
        stream: true,
        reasoning: true,
      },
    },
    {
      name: "GPT-OSS-120B-64k",
      provider: "ollama",
      model: "gpt-oss:120B-64k",
      apiBase: "http://172.17.200.54:11434",
      roles: [],
      capabilities: ["tool_use", "reasoning"],
      defaultCompletionOptions: {
        temperature: 0.6,
        maxTokens: 1024,
        stream: true,
        reasoning: true,
      },
    },
    {
      name: "Qwen2.5",
      provider: "ollama",
      model: "qwen2.5-coder-custom:latest",
      apiBase: "http://172.17.200.54:11437",
      capabilities: ["tool_use"],
      roles: ["autocomplete"],
    },
    {
      name: "Instinct",
      provider: "ollama",
      model: "nate/instinct:latest",
      apiBase: "http://172.17.200.54:11437",
      capabilities: ["tool_use"],
      roles: ["autocomplete"],
    },
  ],
  context: [],
};
